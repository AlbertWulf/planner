"""
MCTS (Monte Carlo Tree Search) æœç´¢å¼•æ“

å€Ÿé‰´ DocETL çš„ MOARSearch å®ç°ï¼Œç”¨äºæ¢ç´¢ pipeline é…ç½®ç©ºé—´ã€‚
"""

from typing import Optional, Callable, Dict, Any, List
import random
import time
from planner.core.pipeline import Pipeline
from planner.core.node import Node, ExecutionMetrics
from planner.optimizer.pareto import ParetoFrontier
from planner.optimizer.actions import ActionGenerator


class MCTSSearchEngine:
    """
    åŸºäº MCTS çš„ pipeline ä¼˜åŒ–æœç´¢å¼•æ“ã€‚
    
    æ ¸å¿ƒæµç¨‹ï¼š
    1. Selection: ä»æ ¹èŠ‚ç‚¹é€‰æ‹©æœ€æœ‰å¸Œæœ›çš„å¶å­èŠ‚ç‚¹
    2. Expansion: æ‰©å±•è¯¥èŠ‚ç‚¹ï¼Œç”Ÿæˆå­èŠ‚ç‚¹
    3. Simulation: æ‰§è¡Œ pipeline å¹¶è¯„ä¼°
    4. Backpropagation: å›æº¯æ›´æ–°èŠ‚ç‚¹ç»Ÿè®¡ä¿¡æ¯
    """
    
    def __init__(
        self,
        root_pipeline: Pipeline,
        executor_func: Callable[[Pipeline], ExecutionMetrics],
        max_iterations: int = 50,
        exploration_weight: float = 1.414,
        max_children_per_node: int = 5,
        verbose: bool = True
    ):
        """
        åˆå§‹åŒ– MCTS æœç´¢å¼•æ“ã€‚
        
        Args:
            root_pipeline: åˆå§‹ pipeline é…ç½®
            executor_func: æ‰§è¡Œå™¨å‡½æ•°ï¼Œæ¥æ”¶ Pipelineï¼Œè¿”å› ExecutionMetrics
            max_iterations: æœ€å¤§æœç´¢è¿­ä»£æ¬¡æ•°
            exploration_weight: UCB æ¢ç´¢æƒé‡
            max_children_per_node: æ¯ä¸ªèŠ‚ç‚¹æœ€å¤§å­èŠ‚ç‚¹æ•°
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        self.root = Node(pipeline=root_pipeline, action_description="root")
        self.executor_func = executor_func
        self.max_iterations = max_iterations
        self.exploration_weight = exploration_weight
        self.max_children_per_node = max_children_per_node
        self.verbose = verbose
        
        # æœç´¢ç»Ÿè®¡
        self.iteration_count = 0
        self.total_evaluations = 0
        self.start_time = 0.0
        
        # Pareto å‰æ²¿
        self.pareto_frontier = ParetoFrontier()
        
        # åŠ¨ä½œç”Ÿæˆå™¨
        self.action_generator = ActionGenerator()
        
        # å·²è®¿é—®èŠ‚ç‚¹ï¼ˆå»é‡ï¼‰
        self.visited_pipeline_hashes = set()
    
    def search(self) -> ParetoFrontier:
        """
        æ‰§è¡Œ MCTS æœç´¢ã€‚
        
        Returns:
            Pareto å‰æ²¿
        """
        self.start_time = time.time()
        self.log("ğŸš€ å¼€å§‹ MCTS æœç´¢...")
        
        # è¯„ä¼°æ ¹èŠ‚ç‚¹
        self.log("ğŸ“Š è¯„ä¼°åˆå§‹ pipeline...")
        self._simulate(self.root)
        self.pareto_frontier.add_node(self.root)
        
        # è¿­ä»£æœç´¢
        for iteration in range(self.max_iterations):
            self.iteration_count = iteration + 1
            
            self.log(f"\n{'='*60}")
            self.log(f"ğŸ” è¿­ä»£ {self.iteration_count}/{self.max_iterations}")
            
            # 1. Selection: é€‰æ‹©æœ€æœ‰å¸Œæœ›çš„èŠ‚ç‚¹
            selected_node = self._select(self.root)
            
            if selected_node is None:
                self.log("âš ï¸  æ— æ³•é€‰æ‹©èŠ‚ç‚¹ï¼Œæœç´¢ç»“æŸ")
                break
            
            self.log(f"âœ“ é€‰ä¸­èŠ‚ç‚¹: depth={selected_node.get_depth()}, "
                    f"visits={selected_node.visits}")
            
            # 2. Expansion: æ‰©å±•èŠ‚ç‚¹
            children = self._expand(selected_node)
            
            if not children:
                self.log("âš ï¸  æ— æ³•æ‰©å±•èŠ‚ç‚¹ï¼Œæ ‡è®°ä¸ºå·²è®¿é—®")
                # å³ä½¿æ— æ³•ç”Ÿæˆå­èŠ‚ç‚¹ï¼Œä¹Ÿè¦å¢åŠ  visitsï¼Œé¿å…ä¸‹æ¬¡å†æ¬¡é€‰ä¸­
                selected_node.visits += 1
                continue
            
            self.log(f"âœ“ ç”Ÿæˆ {len(children)} ä¸ªå­èŠ‚ç‚¹")
            
            # 3. Simulation: éšæœºé€‰æ‹©ä¸€ä¸ªå­èŠ‚ç‚¹è¿›è¡Œè¯„ä¼°
            child_to_simulate = random.choice(children)
            self.log(f"âœ“ é€‰æ‹©å­èŠ‚ç‚¹è¿›è¡Œæ¨¡æ‹Ÿ: {child_to_simulate.action_description[:50]}")
            
            metrics = self._simulate(child_to_simulate)
            
            if metrics:
                # 4. Backpropagation: å›æº¯æ›´æ–°
                reward = self._calculate_reward(metrics)
                child_to_simulate.backpropagate(reward)
                
                # å°è¯•æ·»åŠ åˆ° Pareto å‰æ²¿
                if self.pareto_frontier.add_node(child_to_simulate):
                    self.log(f"âœ¨ æ–° Pareto ç‚¹! Accuracy={metrics.accuracy:.3f}, "
                            f"Tokens={metrics.tokens}, Time={metrics.execution_time:.2f}s")
            
            # è¾“å‡ºå½“å‰çŠ¶æ€
            elapsed = time.time() - self.start_time
            self.log(f"\nğŸ“ˆ å½“å‰ç»Ÿè®¡:")
            self.log(f"   - Pareto å‰æ²¿å¤§å°: {self.pareto_frontier.size()}")
            self.log(f"   - æ€»è¯„ä¼°æ¬¡æ•°: {self.total_evaluations}")
            self.log(f"   - å·²ç”¨æ—¶é—´: {elapsed:.1f}s")
        
        self.log(f"\n{'='*60}")
        self.log(f"âœ… æœç´¢å®Œæˆ!")
        self.log(f"   - æ€»è¿­ä»£: {self.iteration_count}")
        self.log(f"   - Pareto å‰æ²¿: {self.pareto_frontier.size()} ä¸ªè§£")
        self.log(f"   - æ€»æ—¶é—´: {time.time() - self.start_time:.1f}s")
        
        return self.pareto_frontier
    
    def _select(self, node: Node) -> Optional[Node]:
        """
        Selection é˜¶æ®µ: ä½¿ç”¨ UCB é€‰æ‹©æœ€æœ‰å¸Œæœ›çš„å¶å­èŠ‚ç‚¹ã€‚
        
        Args:
            node: èµ·å§‹èŠ‚ç‚¹
        
        Returns:
            é€‰ä¸­çš„å¶å­èŠ‚ç‚¹
        """
        current = node
        
        while not current.is_leaf():
            # å¦‚æœèŠ‚ç‚¹æœªå®Œå…¨æ‰©å±•ï¼Œè¿”å›å®ƒ
            if not current.is_fully_expanded():
                return current
            
            # é€‰æ‹© UCB åˆ†æ•°æœ€é«˜çš„å­èŠ‚ç‚¹
            current = max(
                current.children,
                key=lambda c: c.get_ucb_score(self.exploration_weight)
            )
        
        return current
    
    def _expand(self, node: Node) -> List[Node]:
        """
        Expansion é˜¶æ®µ: ç”Ÿæˆå­èŠ‚ç‚¹ã€‚
        
        Args:
            node: è¦æ‰©å±•çš„èŠ‚ç‚¹
        
        Returns:
            ç”Ÿæˆçš„å­èŠ‚ç‚¹åˆ—è¡¨
        """
        # ä½¿ç”¨åŠ¨ä½œç”Ÿæˆå™¨åˆ›å»ºå­èŠ‚ç‚¹
        children = self.action_generator.generate_children(
            node,
            max_children=self.max_children_per_node
        )
        
        # è¿‡æ»¤å·²è®¿é—®çš„ pipeline
        unique_children = []
        for child in children:
            pipeline_hash = child.pipeline.get_hash()
            if pipeline_hash not in self.visited_pipeline_hashes:
                self.visited_pipeline_hashes.add(pipeline_hash)
                unique_children.append(child)
                node.add_child(child)
        
        return unique_children
    
    def _simulate(self, node: Node) -> Optional[ExecutionMetrics]:
        """
        Simulation é˜¶æ®µ: æ‰§è¡Œ pipeline å¹¶è¯„ä¼°ã€‚
        
        Args:
            node: è¦è¯„ä¼°çš„èŠ‚ç‚¹
        
        Returns:
            æ‰§è¡ŒæŒ‡æ ‡
        """
        if node.is_evaluated:
            return node.metrics
        
        try:
            # æ‰§è¡Œ pipeline
            metrics = self.executor_func(node.pipeline)
            node.update_metrics(metrics)
            self.total_evaluations += 1
            
            return metrics
        
        except Exception as e:
            self.log(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
            node.mark_evaluation_failed()
            return None
    
    def _calculate_reward(self, metrics: ExecutionMetrics) -> float:
        """
        è®¡ç®—å¥–åŠ±å€¼ï¼ˆç”¨äºå›æº¯ï¼‰ã€‚
        
        å¯¹äºä¸‰ç›®æ ‡ä¼˜åŒ–ï¼Œä½¿ç”¨åŠ æƒå’Œï¼š
        reward = w1 * accuracy - w2 * normalized_tokens - w3 * normalized_time
        
        Args:
            metrics: æ‰§è¡ŒæŒ‡æ ‡
        
        Returns:
            å¥–åŠ±å€¼
        """
        # ç®€åŒ–å®ç°ï¼šç­‰æƒé‡å½’ä¸€åŒ–
        # å®é™…åº”ç”¨ä¸­å¯ä»¥æ ¹æ®ç›®æ ‡ä¼˜å…ˆçº§è°ƒæ•´æƒé‡
        
        # ç²¾åº¦è´¡çŒ®ï¼ˆ0-1ï¼‰
        accuracy_reward = metrics.accuracy
        
        # Token æƒ©ç½šï¼ˆå½’ä¸€åŒ–åˆ° 0-1ï¼‰
        # å‡è®¾ 10000 tokens ä¸ºåŸºå‡†
        token_penalty = min(metrics.tokens / 10000.0, 1.0)
        
        # æ—¶é—´æƒ©ç½šï¼ˆå½’ä¸€åŒ–åˆ° 0-1ï¼‰
        # å‡è®¾ 60 ç§’ä¸ºåŸºå‡†
        time_penalty = min(metrics.execution_time / 60.0, 1.0)
        
        # ç»¼åˆå¥–åŠ±ï¼ˆç²¾åº¦æƒé‡æ›´é«˜ï¼‰
        reward = (
            2.0 * accuracy_reward -
            0.5 * token_penalty -
            0.5 * time_penalty
        )
        
        return reward
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "iterations": self.iteration_count,
            "total_evaluations": self.total_evaluations,
            "pareto_size": self.pareto_frontier.size(),
            "elapsed_time": time.time() - self.start_time,
            "root_visits": self.root.visits
        }
    
    def log(self, message: str):
        """æ‰“å°æ—¥å¿—"""
        if self.verbose:
            print(message)
